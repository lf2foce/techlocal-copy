import random
from sqlalchemy.orm import Session
from database.models import ContentPost, Campaign, Theme as DBTheme
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, ValidationError
from google import genai
from google.genai import types
import json
import time
import os
import random
from dotenv import load_dotenv
from google import genai
from google.genai import types
from pydantic import BaseModel
from schemas import Plan, ThemeBase
import asyncio

load_dotenv()

# def generate_theme_title_and_story(campaign_title: str, insight: str) -> tuple[str, str]:
#     title_templates = [
#         "The Power of {keyword}",
#         "Mastering {keyword} for Growth",
#         "Why {keyword} Matters Now",
#         "{keyword}: A New Approach",
#         "Unlocking {keyword}"
#     ]

#     insight_keywords = insight.split()
#     keyword = random.choice(insight_keywords if insight_keywords else ["change"])
#     title = random.choice(title_templates).format(keyword=keyword.capitalize())

#     story = f"This theme explores how '{keyword}' relates to {campaign_title.lower()}. We‚Äôll break down why this is crucial and how to apply it practically."
#     return title, story



# class Theme(BaseModel):
#     title: str
#     story: str
#     content_plan: List[Plan]


class ThemeGenerate(BaseModel):
    themes: List[ThemeBase]

def generate_theme_title_and_story(campaign_title: str, insight: str, description: str, target_customer:str, post_num: int):
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    
    system_prompt=f""" T·∫°o 3 th∆∞∆°ng hi·ªáu cho pages v·ªõi c√°c th√¥ng tin {insight} {target_customer}. 
    M·ªói th∆∞∆°ng hi·ªáu ph·∫£i c√≥ title v√† story kh√°c nhau, v√† content_plan theo chi·∫øn l∆∞·ª£c t·ª´ {description} 
    content_plan n·ªôi dung k·∫ø ho·∫°ch cho {post_num} n·ªôi dung. 
    Vi·∫øt b·∫±ng ti·∫øng vi·ªát
        """
    # Generate response using Gemini API (synchronous version)
    response = client.models.generate_content(
        model='gemini-2.0-flash',  # Updated to newer model version
        contents=f"Vi·∫øt cho t√¥i n·ªôi dung cho 3 th∆∞∆°ng hi·ªáu chi·∫øn l∆∞·ª£c d·ª±a tr√™n {description}",
        config=types.GenerateContentConfig(
            response_mime_type='application/json',
            response_schema=ThemeGenerate,
            system_instruction=types.Part.from_text(text=system_prompt),
        ),
    )
    
    # Extract the response
    print("Generated 3 themes with content plans based on user prompt.")

    content = json.loads(response.text)
    
    # Validate and parse the response using Pydantic
    themes_data = ThemeGenerate(**content)
    print(themes_data)
    # Convert list of themes to list of tuples using dot notation for Pydantic model attributes

    return [
        {
            "title": theme.title,
            "story": theme.story,
            "content_plan": theme.content_plan.model_dump()
        }
        for theme in themes_data.themes
    ]

from schemas import PostMetadata
class BlogPost(BaseModel):
    title: str
    content: str

async def generate_post_content(theme_title: str, theme_story: str, campaign_title: str, content_plan: Dict[str, Any]) -> Dict[str, Any]:
    """Generate a post content using Google Gemini API asynchronously."""
    print(f"üîÑ Starting generation of post with title: '{content_plan.get('title')}' for theme: '{theme_title}'")
    start_time = time.time()
    try:
        # Initialize the client
        client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
        
        # Extract content plan metadata
        goal = content_plan.get('goal')
        format_type = content_plan.get('format')
        content_idea = content_plan.get('content_idea')
        print(content_idea)
        post_title = content_plan.get('title')
        
        prompt = (
                f"D·ª±a v√†o t√™n th∆∞∆°ng hi·ªáu '{theme_title}', m√¥ t·∫£ k√™nh, v√† y√™u c·∫ßu c·ª• th·ªÉ cho ng√†y h√¥m nay, h√£y vi·∫øt m·ªôt b√†i ƒëƒÉng d·∫°ng {format_type} b·∫±ng ti·∫øng Vi·ªát.\n\n"
                f"--- T√äN TH∆Ø∆†NG HI·ªÜU ---\n{theme_title}\n\n"
                f"--- M√î T·∫¢ K√äNH ---\n{theme_story}\n\n"
                f"--- M·ª§C TI√äU B√ÄI VI·∫æT ---\n{goal}\n\n"
                f"--- √ù T∆Ø·ªûNG N·ªòI DUNG ---\n{content_idea}\n\n"
                f"--- Y√äU C·∫¶U ---\n"
                f"- Gi·ªçng vƒÉn: G·∫ßn g≈©i, ch√¢n th·∫≠t, ƒë·ªìng c·∫£m, truy·ªÅn c·∫£m h·ª©ng. C√≥ th·ªÉ th√™m h√†i h∆∞·ªõc/suy t∆∞ t√πy ch·ªß ƒë·ªÅ.\n"
                f"- C·∫•u tr√∫c: M·ªü ƒë·∫ßu thu h√∫t, th√¢n ph√°t tri·ªÉn √Ω, k·∫øt b√†i √Ω nghƒ©a.\n"
                f"- K·∫øt b√†i: Khuy·∫øn kh√≠ch t∆∞∆°ng t√°c (c√¢u h·ªèi m·ªü) ho·∫∑c ƒë∆∞a ra l·ªùi kh√≠ch l·ªá/h√†nh ƒë·ªông nh·ªè.\n"
                f"- QUAN TR·ªåNG: S·ª≠ d·ª•ng emoji (VD: üí°ü§îüí™‚ù§Ô∏èüôèüò¢üìàü§ùüåü‚ú®) ph√π h·ª£p, t·ª± nhi√™n ƒë·ªÉ tƒÉng bi·ªÉu c·∫£m. ƒê·ª´ng l·∫°m d·ª•ng.\n\n"
                "Output: ONLY a valid JSON object with a single key 'post_content' containing the full Vietnamese post as a single string."
            )

        # System prompt for content generation
        system_prompt = """
        You are an expert AI assistant specializing in creating social media content and assets based on provided campaign knowledge and specific instructions. Your tasks include:
            1. Generating creative Vietnamese brand names relevant to the campaign context.
            2. Creating content schedules (Vietnamese topics/quotes) aligned with the campaign strategy for a specified number of days.
            3. Writing full Vietnamese storytelling posts reflecting the campaign's tone, themes, and target audience, using the provided context for a specific day.
            4. Evaluating and improving posts based on relevance, insight, value, emotion, tone, emoji use, and call to action.
            Output ONLY the valid JSON object without surrounding text or markdown.
            Language: Primarily Vietnamese
        """
        
        # Generate response using Gemini API
        response = client.models.generate_content(
            # model='gemini-2.5-flash-preview-04-17',  # Updated model version
            model='gemini-2.0-flash',  # Updated model version
            contents=prompt,
            config={
                'response_mime_type': 'application/json',
                'response_schema': BlogPost,
                'system_instruction': types.Part.from_text(text=system_prompt),
            },
        )
        
        # Inside generate_post_content function
        # Extract and parse the response
        content = json.loads(response.text)
        blog_post = BlogPost(**content)
       
        # T·∫°o metadata cho b√†i vi·∫øt
        post_metadata = PostMetadata(
            content_type=content_plan.get('format'),
            content_ideas=content_plan.get('content_idea'),
            goals=content_plan.get('goal'),
            content_length=len(blog_post.content)
        )
        
        elapsed_time = time.time() - start_time
        print(f"‚úÖ Completed post in {elapsed_time:.2f} seconds. Title: '{post_title}'")
        
        return {
            "title": blog_post.title,
            "content": blog_post.content,
            "post_metadata": post_metadata.model_dump()
        }
    except Exception as e:
        # Log the error but don't raise it to allow other posts to be generated
        elapsed_time = time.time() - start_time
        print(f"‚ùå Error generating post after {elapsed_time:.2f} seconds: {str(e)}")
        return {
            "title": content_plan.get('title'),
            "content": f"This post is based on theme: '{theme_title}'\n\n{theme_story}\n\nGenerated for campaign '{campaign_title}'.",
            "post_metadata": None
        }

async def create_default_content_plan(theme_title: str, theme_story: str, num_posts=5) -> Dict[str, Any]:
    """T·∫°o content plan m·∫∑c ƒë·ªãnh khi kh√¥ng c√≥ plan ƒë∆∞·ª£c cung c·∫•p"""
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    
    prompt = f"""
    T·∫°o k·∫ø ho·∫°ch n·ªôi dung cho ch·ªß ƒë·ªÅ '{theme_title}' v·ªõi {num_posts} b√†i vi·∫øt.
    M√¥ t·∫£ ch·ªß ƒë·ªÅ: {theme_story}
    M·ªói b√†i vi·∫øt c·∫ßn c√≥:
    - goal: M·ª•c ti√™u n·ªôi dung
    - title: Ti√™u ƒë·ªÅ b√†i vi·∫øt 
    - format: ƒê·ªãnh d·∫°ng (b√†i vi·∫øt/infographic/video)
    - content_idea: √ù t∆∞·ªüng n·ªôi dung ng·∫Øn
    """
    
    response = client.models.generate_content(
        model='gemini-2.0-flash',
        contents=prompt,
        config={
            'response_mime_type': 'application/json',
            'response_schema': Plan
        }
    )
    
    content = json.loads(response.text)
    return content.model_dump()

async def process_with_semaphore(theme_title: str, theme_story: str, campaign_title: str, content_plan: Optional[Dict[str, Any]] = None):
    # Create a semaphore to limit concurrent API calls
    semaphore = asyncio.Semaphore(10)  # Limit to 10 concurrent API calls
    
    # Ensure content_plan is properly formatted
    if content_plan is None:
        print("‚ö†Ô∏è No content plan provided, creating default")
        content_plan = await create_default_content_plan(theme_title, theme_story)
    
    # Handle string content_plan
    if isinstance(content_plan, str):
        try:
            content_plan = json.loads(content_plan)
        except json.JSONDecodeError:
            print("‚ùå Could not parse content_plan JSON string")
            return []
    
    # Validate content_plan structure
    if not isinstance(content_plan, dict) or 'items' not in content_plan:
        print("‚ùå Invalid content plan format or missing 'items' field")
        return []
    
    content_items = content_plan['items']
    if not isinstance(content_items, list) or not content_items:
        print("‚ùå Content items must be a non-empty list")
        return []
    
    # Define the bounded task that will respect the semaphore
    async def bounded_task(item):
        # This critical section ensures only 10 tasks can execute this block concurrently
        async with semaphore:
            print(f"üîÑ Starting generation for item: '{item.get('title')}'")
            try:
                return await generate_post_content(
                    theme_title,
                    theme_story,
                    campaign_title,
                    item
                )
            except Exception as e:
                print(f"‚ùå Error generating post for '{item.get('title')}': {str(e)}")
                return None
    
    # Create tasks for all content items
    tasks = [bounded_task(item) for item in content_items]
    
    # Execute all tasks concurrently with gather, this is the correct way
    print(f"üöÄ Generating {len(tasks)} posts concurrently with max {semaphore._value} at a time")
    start_time = time.time()
    results = await asyncio.gather(*tasks)
    elapsed = time.time() - start_time
    
    # Filter out failed generations and log statistics
    valid_results = [r for r in results if r is not None]
    print(f"‚úÖ Generated {len(valid_results)}/{len(tasks)} posts in {elapsed:.2f}s")
    
    return valid_results


#func test
def save_posts_to_db(post_contents, campaign_id, theme_id, db):
    """Create posts in the database using optimized bulk insert."""
    if not post_contents:
        print("‚ö†Ô∏è No post contents provided to save")
        return 0
        
    now = datetime.now()
    total_posts = len(post_contents)
    print(f"üîÑ Preparing to save {total_posts} posts to database")
    
    # Prepare all posts for bulk insert with minimal object creation overhead
    posts_to_insert = [
        ContentPost(
            campaign_id=campaign_id,
            theme_id=theme_id,
            title=post.get("title", f"Post {i}"),
            content=post.get("content", ""),
            status="approved",
            created_at=now + timedelta(microseconds=i),
            image_status="pending",
            post_metadata=post.get("post_metadata")
        )
        for i, post in enumerate(post_contents)
        if isinstance(post, dict) and post.get("content")
    ]
    
    if not posts_to_insert:
        print("‚ùå No valid posts to insert")
        return 0
    
    try:
        # Execute bulk insert and campaign update in a single transaction
        db.bulk_save_objects(posts_to_insert)
        campaign = db.query(Campaign).filter(Campaign.id == campaign_id).first()
        if campaign:
            campaign.current_step = 4
        db.commit()
        
        created_count = len(posts_to_insert)
        print(f"‚úÖ Successfully saved {created_count}/{total_posts} posts to database")
        return created_count
        
    except Exception as e:
        db.rollback()
        print(f"‚ùå Error during bulk save operation: {str(e)}")
        return 0

async def generate_posts_from_theme(theme: DBTheme, db_factory, campaign_data: Dict[str, Any] = None) -> int:
    """Generate posts for a theme using concurrent processing with separate DB sessions"""
    print(f"üöÄ Starting post generation for theme ID: {theme.id}")
    
    # Use a separate DB session for the main function
    with db_factory() as db:
        campaign = db.query(Campaign).filter(Campaign.id == theme.campaign_id).first()
        if not campaign:
            print(f"‚ùå Campaign not found for theme ID: {theme.id}")
            return 0
        
        # Create enriched story with campaign data
        enriched_story = theme.story
        
        # Parse campaign_data if needed
        if isinstance(campaign_data, str):
            try:
                campaign_data = json.loads(campaign_data)
            except json.JSONDecodeError:
                print("‚ùå Failed to parse campaign_data")
                campaign_data = {}
        
        # Enrich the theme story with campaign context
        if campaign_data:
            brand_voice = campaign_data.get('brandVoice', '')
            key_messages = campaign_data.get('keyMessages', [])
            content_guidelines = campaign_data.get('contentGuidelines', '')
            
            enriched_story = f"{theme.story}\n\nBrand Voice: {brand_voice}\n"
            if key_messages:
                enriched_story += f"Key Messages:\n" + "\n".join([f"- {msg}" for msg in key_messages]) + "\n"
            if content_guidelines:
                enriched_story += f"\nContent Guidelines:\n{content_guidelines}"
        
        # Process content_plan
        content_plan = theme.content_plan
        if isinstance(content_plan, str):
            try:
                content_plan = json.loads(content_plan)
            except json.JSONDecodeError:
                print(f"‚ùå Failed to parse content_plan JSON for theme {theme.id}")
                content_plan = None
    
    # Generate posts concurrently - note we're outside the DB session now
    posts = await process_with_semaphore(
        theme.title,
        enriched_story,
        campaign.title,
        content_plan
    )
    
    if not posts:
        print("‚ùå No posts were generated")
        return 0
    
    # Use a separate DB session for saving results
    with db_factory() as db:
        # Save posts in batches
        total_saved = 0
        batch_size = 10
        for i in range(0, len(posts), batch_size):
            batch = posts[i:i + batch_size]
            batch_posts = []
            
            for post_data in batch:
                post = ContentPost(
                    campaign_id=theme.campaign_id,
                    theme_id=theme.id,
                    title=post_data["title"],
                    content=post_data["content"],
                    post_metadata=post_data.get("post_metadata", ""),
                    status="approved",
                    image_status="pending"
                )
                batch_posts.append(post)
            
            try:
                # Use bulk_save_objects for efficient batch saving
                db.bulk_save_objects(batch_posts)
                db.commit()
                total_saved += len(batch_posts)
                print(f"‚úÖ Saved batch {i//batch_size + 1}/{(len(posts) + batch_size - 1)//batch_size} ({len(batch_posts)} posts)")
            except Exception as e:
                db.rollback()
                print(f"‚ùå Error saving batch: {str(e)}")
        
        return total_saved


def approve_post(post_id: int, db: Session) -> ContentPost:
    post = db.query(ContentPost).filter(ContentPost.id == post_id).first()
    if not post:
        raise ValueError("Post not found")

    post.status = "approved" #"scheduled" "posted"
    db.commit()
    return post
